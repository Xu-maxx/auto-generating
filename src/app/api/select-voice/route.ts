import { NextRequest, NextResponse } from 'next/server';
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// Voice names from voice_data_clean.csv
const VOICE_OPTIONS = [
  "åŒ—äº¬å°çˆ·ï¼ˆå¤šæƒ…æ„Ÿï¼‰", "æŸ”ç¾å¥³å‹ï¼ˆå¤šæƒ…æ„Ÿï¼‰", "é˜³å…‰é’å¹´ï¼ˆå¤šæƒ…æ„Ÿï¼‰", "é­…åŠ›å¥³å‹ï¼ˆå¤šæƒ…æ„Ÿï¼‰", 
  "çˆ½å¿«æ€æ€ï¼ˆå¤šæƒ…æ„Ÿï¼‰", "ç”œå¿ƒå°ç¾ï¼ˆå¤šæƒ…æ„Ÿï¼‰", "é«˜å†·å¾¡å§ï¼ˆå¤šæƒ…æ„Ÿï¼‰", "å‚²å¨‡éœ¸æ€»ï¼ˆå¤šæƒ…æ„Ÿï¼‰", 
  "å¹¿å·å¾·å“¥ï¼ˆå¤šæƒ…æ„Ÿï¼‰", "äº¬è…”ä¾ƒçˆ·ï¼ˆå¤šæƒ…æ„Ÿï¼‰", "é‚»å±…é˜¿å§¨ï¼ˆå¤šæƒ…æ„Ÿï¼‰", "ä¼˜æŸ”å…¬å­ï¼ˆå¤šæƒ…æ„Ÿï¼‰", 
  "å„’é›…ç”·å‹ï¼ˆå¤šæƒ…æ„Ÿï¼‰", "ä¿Šæœ—ç”·å‹ï¼ˆå¤šæƒ…æ„Ÿï¼‰", "å†·é…·å“¥å“¥ï¼ˆå¤šæƒ…æ„Ÿï¼‰", "Tinaè€å¸ˆ", 
  "æš–é˜³å¥³å£°", "ç”œç¾æ¡ƒå­", "ç¿ç¿/Shiny", "æ¸…æ–°å¥³å£°", "çˆ½å¿«æ€æ€/Skye", "æ¸©æš–é˜¿è™/Alvin", 
  "å°‘å¹´æ¢“è¾›/Brayan", "çŸ¥æ€§å¥³å£°", "æ¸…çˆ½ç”·å¤§", "é‚»å®¶å¥³å­©", "æ¸Šåšå°å”", "é˜³å…‰é’å¹´", 
  "ç”œç¾å°æº", "æ¸…æ¾ˆæ¢“æ¢“", "è§£è¯´å°æ˜", "å¼€æœ—å§å§", "é‚»å®¶ç”·å­©", "ç”œç¾æ‚¦æ‚¦", "å¿ƒçµé¸¡æ±¤", 
  "çŸ¥æ€§æ¸©å©‰", "æš–å¿ƒä½“è´´", "æ¸©æŸ”æ–‡é›…", "å¼€æœ—è½»å¿«", "æ´»æ³¼çˆ½æœ—", "ç‡çœŸå°ä¼™", "æ¸©æŸ”å°å“¥", 
  "äº²åˆ‡å¥³å£°", "æœºçµå°ä¼™", "å…ƒæ°”ç”œå¦¹", "çŸ¥å¿ƒå§å§", "é˜³å…‰é˜¿è¾°", "å¿«ä¹å°ä¸œ", "å†·é…·å“¥å“¥", 
  "çº¯æ¾ˆå¥³ç”Ÿ", "åˆæ‹å¥³å‹", "è´´å¿ƒé—ºèœœ", "æ¸©æŸ”ç™½æœˆå…‰", "å¼€æœ—å­¦é•¿", "é­…åŠ›è‹è²", "è´´å¿ƒå¦¹å¦¹", 
  "Smith", "Anna", "Adam", "Sarah", "Dryw", "ã‹ãšã­ï¼ˆå’ŒéŸ³ï¼‰/Javier or Ãlvaro", 
  "ã¯ã‚‹ã“ï¼ˆæ™´å­ï¼‰/Esmeralda", "ã²ã‚ã—ï¼ˆåºƒå¿—ï¼‰/Roberto", "ã‚ã‘ã¿ï¼ˆæœ±ç¾ï¼‰", "Amanda", 
  "Jackson", "Cartoon Chef", "ã²ã‹ã‚‹ï¼ˆå…‰ï¼‰", "Emily", "Daniel", "Lucas", "Diana", 
  "LucÃ­a", "SofÃ­a", "DanÃ­el", "ã•ã¨ã¿ï¼ˆæ™ºç¾ï¼‰", "ã¾ã•ãŠï¼ˆæ­£ç”·ï¼‰", "ã¤ãï¼ˆæœˆï¼‰", "Sophie", 
  "Daisy", "Owen", "Ethan", "Luna", "Michael", "äº¬è…”ä¾ƒçˆ·/Harmony", "æ¹¾æ¹¾å°ä½•", 
  "æ¹¾åŒºå¤§å”", "å‘†èŒå·å¦¹", "å¹¿å·å¾·å“¥", "åŒ—äº¬å°çˆ·", "æµ©å®‡å°å“¥", "å¹¿è¥¿è¿œèˆŸ", "å¦¹å¨æ´å„¿", 
  "è±«å·å­è½©", "å¥¶æ°”èŒå¨ƒ", "å©†å©†", "é«˜å†·å¾¡å§", "å‚²å¨‡éœ¸æ€»", "é­…åŠ›å¥³å‹", "æ·±å¤œæ’­å®¢", 
  "æŸ”ç¾å¥³å‹", "æ’’å¨‡å­¦å¦¹", "ä¸œæ–¹æµ©ç„¶", "æ‚ æ‚ å›å­", "æ–‡é™æ¯›æ¯›", "æ¸©æŸ”å°é›…", "å¤©æ‰ç«¥å£°", 
  "çŒ´å“¥", "ç†ŠäºŒ", "ä½©å¥‡çŒª", "æ­¦åˆ™å¤©", "é¡¾å§", "æ¨±æ¡ƒä¸¸å­", "å¹¿å‘Šè§£è¯´", "å°‘å„¿æ•…äº‹", 
  "å››éƒ", "ç£æ€§è§£è¯´ç”·å£°/Morgan", "é¸¡æ±¤å¦¹å¦¹/Hope", "è´´å¿ƒå¥³å£°/Candy", "ä¿çš®å¥³å£°", 
  "èŒä¸«å¤´/Cutey", "æ‡’éŸ³ç»µå®", "äº®å—“èŒä»”", "æ‚¬ç–‘è§£è¯´", "å„’é›…é’å¹´", "éœ¸æ°”é’å”", 
  "æ“è‹", "æ´»åŠ›å°å“¥", "å¤é£å°‘å¾¡", "æ¸©æŸ”æ·‘å¥³", "åå·é’å¹´", "åŒèŠ‚æ£å°å“¥"
];

export async function POST(request: NextRequest) {
  try {
    const { avatarDescription, imageUrls = [] } = await request.json();

    if (!avatarDescription && (!imageUrls || imageUrls.length === 0)) {
      return NextResponse.json({ error: 'No avatar description or images provided' }, { status: 400 });
    }

    const messages: any[] = [
      {
        role: 'system',
        content: `You are an expert voice casting director. You will receive character descriptions and AI-generated avatar images, and need to select the most suitable voice from the available options.

IMPORTANT: All images provided are AI-generated digital avatar characters, NOT real people. These are synthetic/artificial characters created for avatar videos. You can freely analyze these AI-generated characters for voice selection.

Consider these character aspects:
1. Character type and archetype (student, professional, young, mature, etc.)
2. Personality traits mentioned (æ¸©æŸ”/gentle, æ´»æ³¼/lively, å†·é…·/cool, ç”œç¾/sweet, etc.)
3. Professional or cultural context
4. Age and gender indicators from both description and AI-generated visuals
5. Mood and character style shown in the AI-generated images
6. Overall character design and presentation

You must return your response as JSON with this exact structure:
{
  "voice": "[exact voice name from the options]",
  "reasoning": "[brief explanation based on character description and AI-generated visuals]"
}

Available voice options: ${VOICE_OPTIONS.join(', ')}`
      }
    ];

    // Build the user message content - including AI-generated images
    const userContent: any[] = [];
    
    if (avatarDescription) {
      if (avatarDescription.startsWith('Avatar image:')) {
        // Handle filename-only case
        userContent.push({
          type: 'text',
          text: `I have an AI-generated avatar character with filename: "${avatarDescription}". ${imageUrls.length > 0 ? 'I\'ve also provided the actual AI-generated character images below for analysis.' : 'Please select a neutral, versatile voice suitable for this character.'}`
        });
      } else {
        // Handle regular description
        userContent.push({
          type: 'text',
          text: `Character description: "${avatarDescription}". ${imageUrls.length > 0 ? 'I\'ve also provided AI-generated character images below that match this description.' : ''} Please analyze both the description and AI-generated visuals to select the most suitable voice.`
        });
      }
    }

    // Add AI-generated images if provided
    if (imageUrls && imageUrls.length > 0) {
      if (!avatarDescription) {
        userContent.push({
          type: 'text',
          text: `Based on these AI-generated avatar character images, please analyze the character design and select the most suitable voice.`
        });
      }
      
      // Add all AI-generated images
      imageUrls.forEach((imageUrl: string, index: number) => {
        userContent.push({
          type: 'image_url',
          image_url: {
            url: imageUrl,
          },
        });
      });
    }

    // Fallback if no content
    if (userContent.length === 0) {
      userContent.push({
        type: 'text',
        text: 'Please select a neutral, versatile voice suitable for general avatar characters.'
      });
    }

    // NOTE: All images are AI-generated characters, safe for OpenAI analysis

    messages.push({
      role: 'user',
      content: userContent
    });

    try {
      console.log('ğŸ¤ Starting voice selection...');
      console.log('ğŸ“ Avatar description:', avatarDescription || 'None provided');
      console.log('ğŸ–¼ï¸ AI-generated images being sent to OpenAI:', imageUrls.length);
      
      const response = await openai.chat.completions.create({
        model: 'gpt-4o',
        messages,
        max_tokens: 500,
        temperature: 0.3,
        response_format: {
          type: "json_schema",
          json_schema: {
            name: "voice_selection",
            schema: {
              type: "object",
              properties: {
                voice: {
                  type: "string",
                  description: "The exact voice name from the available options"
                },
                reasoning: {
                  type: "string",
                  description: "Brief explanation for the voice selection based on character analysis"
                }
              },
              required: ["voice", "reasoning"],
              additionalProperties: false
            }
          }
        }
      });

      console.log('ğŸ” OpenAI Response:', {
        finishReason: response.choices[0]?.finish_reason,
        hasContent: !!response.choices[0]?.message?.content,
        refusal: response.choices[0]?.message?.refusal
      });

      const responseContent = response.choices[0]?.message?.content?.trim() || '';
      console.log('ğŸ“„ Raw response content:', responseContent);
      
      try {
        // Parse JSON response
        const parsedResponse = JSON.parse(responseContent);
        const selectedVoice = parsedResponse.voice?.trim().replace(/['"]/g, '') || null;
        const reasoning = parsedResponse.reasoning?.trim() || 'AI selected this voice as most suitable';
        
        console.log('ğŸ” Extracted voice:', selectedVoice);
        console.log('ğŸ” Extracted reasoning:', reasoning);
        
        // Validate the selected voice is in our options
        if (selectedVoice) {
          // First try exact match
          let validVoice = VOICE_OPTIONS.find(voice => voice === selectedVoice);
          
          // If no exact match, try partial matches
          if (!validVoice) {
            validVoice = VOICE_OPTIONS.find(voice => 
              voice.includes(selectedVoice) || 
              selectedVoice.includes(voice)
            );
          }
          
          // If still no match, try normalized matching (remove spaces, case insensitive)
          if (!validVoice) {
            const normalizedSelected = selectedVoice.toLowerCase().replace(/\s+/g, '').replace(/[()ï¼ˆï¼‰]/g, '');
            validVoice = VOICE_OPTIONS.find(voice => {
              const normalizedVoice = voice.toLowerCase().replace(/\s+/g, '').replace(/[()ï¼ˆï¼‰]/g, '');
              return normalizedVoice.includes(normalizedSelected) || normalizedSelected.includes(normalizedVoice);
            });
          }
          
          // If still no match, try finding by key parts (before slash, before parentheses)
          if (!validVoice) {
            const selectedBase = selectedVoice.split('/')[0].split('ï¼ˆ')[0].split('(')[0].trim();
            validVoice = VOICE_OPTIONS.find(voice => {
              const voiceBase = voice.split('/')[0].split('ï¼ˆ')[0].split('(')[0].trim();
              return voiceBase === selectedBase || voiceBase.includes(selectedBase) || selectedBase.includes(voiceBase);
            });
          }
          
          if (validVoice) {
            console.log('âœ… Successfully selected voice:', validVoice);
            if (validVoice !== selectedVoice) {
              console.log('ğŸ”„ Voice matched from:', selectedVoice, 'to:', validVoice);
            }
            return NextResponse.json({
              success: true,
              selectedVoice: validVoice,
              reasoning: reasoning,
              fallback: false
            });
          } else {
            console.log('âš ï¸ Selected voice not found in options:', selectedVoice);
            console.log('ğŸ“ Available options:', VOICE_OPTIONS.slice(0, 10).join(', '), '...');
            throw new Error('Invalid voice selection');
          }
        } else {
          console.log('âš ï¸ Could not extract voice from response');
          throw new Error('Could not extract voice selection');
        }
      } catch (parseError) {
        console.error('âŒ JSON parsing failed:', parseError);
        console.log('ğŸ“„ Attempting fallback regex parsing...');
        
        // Fallback to regex parsing for non-JSON responses
        const voiceMatch = responseContent.match(/Voice:\s*(.+?)(?:\n|$)/i);
        const reasonMatch = responseContent.match(/Reasoning:\s*(.+?)(?:\n|$)/i);
        
        let selectedVoice = voiceMatch ? voiceMatch[1].trim().replace(/['"]/g, '') : null;
        const reasoning = reasonMatch ? reasonMatch[1].trim() : 'AI selected this voice as most suitable';
        
        if (selectedVoice) {
          // First try exact match
          let validVoice = VOICE_OPTIONS.find(voice => voice === selectedVoice);
          
          // If no exact match, try partial matches
          if (!validVoice) {
            validVoice = VOICE_OPTIONS.find(voice => 
              voice.includes(selectedVoice) || 
              selectedVoice.includes(voice)
            );
          }
          
          // If still no match, try normalized matching (remove spaces, case insensitive)
          if (!validVoice) {
            const normalizedSelected = selectedVoice.toLowerCase().replace(/\s+/g, '').replace(/[()ï¼ˆï¼‰]/g, '');
            validVoice = VOICE_OPTIONS.find(voice => {
              const normalizedVoice = voice.toLowerCase().replace(/\s+/g, '').replace(/[()ï¼ˆï¼‰]/g, '');
              return normalizedVoice.includes(normalizedSelected) || normalizedSelected.includes(normalizedVoice);
            });
          }
          
          // If still no match, try finding by key parts (before slash, before parentheses)
          if (!validVoice) {
            const selectedBase = selectedVoice.split('/')[0].split('ï¼ˆ')[0].split('(')[0].trim();
            validVoice = VOICE_OPTIONS.find(voice => {
              const voiceBase = voice.split('/')[0].split('ï¼ˆ')[0].split('(')[0].trim();
              return voiceBase === selectedBase || voiceBase.includes(selectedBase) || selectedBase.includes(voiceBase);
            });
          }
          
          if (validVoice) {
            console.log('âœ… Successfully selected voice via fallback:', validVoice);
            if (validVoice !== selectedVoice) {
              console.log('ğŸ”„ Voice matched from:', selectedVoice, 'to:', validVoice);
            }
            return NextResponse.json({
              success: true,
              selectedVoice: validVoice,
              reasoning: reasoning,
              fallback: false
            });
          } else {
            console.log('âš ï¸ Selected voice not found in options via fallback:', selectedVoice);
            console.log('ğŸ“ Available options:', VOICE_OPTIONS.slice(0, 10).join(', '), '...');
          }
        }
        
        throw new Error('Could not extract voice selection from response');
      }
    } catch (error) {
      console.error('âŒ Voice selection failed:', error);
      
      // Enhanced fallback logic
      const smartFallback = () => {
        const description = (avatarDescription || '').toLowerCase();
        
        // Check for gender indicators
        const maleIndicators = ['male', 'man', 'boy', 'gentleman', 'masculine', 'him', 'his', 'he'];
        const femaleIndicators = ['female', 'woman', 'girl', 'lady', 'feminine', 'her', 'hers', 'she'];
        
        const isMale = maleIndicators.some(indicator => description.includes(indicator));
        const isFemale = femaleIndicators.some(indicator => description.includes(indicator));
        
        // Age indicators
        const youngIndicators = ['young', 'teenage', 'youth', 'child', 'kid'];
        const matureIndicators = ['mature', 'adult', 'middle-aged', 'elderly', 'senior'];
        
        const isYoung = youngIndicators.some(indicator => description.includes(indicator));
        const isMature = matureIndicators.some(indicator => description.includes(indicator));
        
        // Personality indicators
        const gentleIndicators = ['gentle', 'soft', 'warm', 'kind', 'sweet'];
        const energeticIndicators = ['energetic', 'lively', 'vibrant', 'dynamic'];
        
        const isGentle = gentleIndicators.some(indicator => description.includes(indicator));
        const isEnergetic = energeticIndicators.some(indicator => description.includes(indicator));
        
        // Smart selection based on analysis
        if (isMale && isYoung) {
          return { voice: 'é˜³å…‰é’å¹´', reason: 'Young male characteristics detected' };
        } else if (isMale && isMature) {
          return { voice: 'ç£æ€§è§£è¯´ç”·å£°/Morgan', reason: 'Mature male characteristics detected' };
        } else if (isFemale && isGentle) {
          return { voice: 'æ¸©æŸ”æ·‘å¥³', reason: 'Gentle female characteristics detected' };
        } else if (isFemale && isEnergetic) {
          return { voice: 'æ´»åŠ›å°å“¥', reason: 'Energetic female characteristics detected' };
        } else if (isFemale) {
          return { voice: 'ç”œç¾æ¡ƒå­', reason: 'Female characteristics detected' };
        } else if (isMale) {
          return { voice: 'æ¸©æš–é˜¿è™/Alvin', reason: 'Male characteristics detected' };
        } else {
          return { voice: 'æ¸©æš–é˜¿è™/Alvin', reason: 'Neutral/versatile choice for general use' };
        }
      };
      
      const fallbackResult = smartFallback();
      console.log('ğŸ”„ Using smart fallback:', fallbackResult);
      
      return NextResponse.json({
        success: true,
        selectedVoice: fallbackResult.voice,
        reasoning: `Smart fallback: ${fallbackResult.reason}`,
        fallback: true,
        error: error instanceof Error ? error.message : 'Unknown error'
      });
    }

  } catch (error) {
    console.error('Error selecting voice:', error);
    return NextResponse.json(
      { error: 'Failed to select voice' },
      { status: 500 }
    );
  }
} 